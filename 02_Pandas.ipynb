{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOwR6fiCD/SksLqJ3n+Etz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joshcova/NLP_Workshop/blob/main/02_Pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data wrangling in Pandas"
      ],
      "metadata": {
        "id": "pt8a6gULC1pR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this workshop we will cover basic data manipulation tasks. To do this we will be using the popular `pandas` library.\n",
        "\n",
        "Libraries are a collection of in-built functions by other Python users that allow us to work more efficiently.\n",
        "\n",
        "Thankfully the libraries that we will be working with are for the most part already downloaded in the google colab programming environment, but if not we would first need to install them (`pip install`).\n",
        "\n",
        "After installing a library, you need to load it into your programming environment (`import`)\n",
        "\n",
        "At its core, pandas introduces two primary data structures: `Series` (one-dimensional labeled arrays) and `DataFrame` (two-dimensional labeled data structures). For quantitative text analysis, `DataFrames` will be our \"workhorse\", providing a flexible and efficient way to store, process, and analyze collections of text documents and their associated metadata."
      ],
      "metadata": {
        "id": "hrU_qyUvUmZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Now we can use pandas' in-built functions.\n",
        "# Given that we will often call functions of the pandas library, it is a conventition to specify import pandas as pd so that we only have to write pd. as opposed to pandas. when calling\n",
        "# Pandas' in-built functions"
      ],
      "metadata": {
        "id": "AN5s_BAeU0Gf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let us create some \"dummy\" data"
      ],
      "metadata": {
        "id": "QlfeQ4wdV99t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    \"doc_id\": [1, 2, 3, 4],\n",
        "    \"author\": [\"Party A\", \"Party B\", \"Party A\", \"Party B\"],\n",
        "    \"year\": [2020, 2020, 2021, 2021],\n",
        "    \"text\": [\n",
        "        \"The economy is growing rapidly.\",\n",
        "        \"Immigration is a major political issue.\",\n",
        "        \"The economy faces a serious crisis.\",\n",
        "        \"A new climate policy was announced.\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df)"
      ],
      "metadata": {
        "id": "pIhRdI2_WdR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is our first dataframe. You can see how a dataframe is a dictionary of lists. To visualize it, think Excel spreadsheet."
      ],
      "metadata": {
        "id": "m7kxsf7BzAQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If you are interested in perusing the contents of only a specific column you can call it by using the square brackets\n",
        "\n",
        "df[\"author\"]"
      ],
      "metadata": {
        "id": "c0Cr_pCdXBMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filtering by a condition\n",
        "\n",
        "df_2021 = df[df[\"year\"]==2021]\n",
        "\n",
        "# In other words, what is going on here is that we are asking Python to look into the column \"year\" of the dataframe object df and only select the rows where the value in the year column\n",
        "# is equal to 2021 (i.e. the year 2021).\n",
        "# Note the use of the double equal sign (==) for checking conditional statements. This is different from the single equal sign that is used to assign variables."
      ],
      "metadata": {
        "id": "1Uu_xVLsXIUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## There are a lot of functions and methods that we can use. Here is one of the most used ones.\n",
        "\n",
        "df_3 = df.rename(columns = {\"author\": \"party\"})\n",
        "\n",
        "## You can visualize the first rows of a dataset by specifying the .head() method\n",
        "\n",
        "df_3.head()\n",
        "\n",
        "## Particularly useful when working with large datasets"
      ],
      "metadata": {
        "id": "xJms4bPiYDBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are many nice things that we can do with the Pandas library. We suggest that you consult the ever-helpful [Pandas cheatsheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)"
      ],
      "metadata": {
        "id": "XEr5uLf40ix_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading in data"
      ],
      "metadata": {
        "id": "k4msTm4BIp22"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Typically (and thankfully), however, we will not be creating data from scratch, we will use data that is already structured in a hopefully appropriate format\n",
        "\n",
        "We will be using as a first dataset a slightly self-serving example, namely Cova and Germani (2025), [CommonsCorpus](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/KXDDJU):\n",
        "\n",
        "An annotated and machine-readable corpus of all UK House of Commons Parliamentary Debates (1970-2024) in .csv format\n",
        "\n",
        "For the purposes of this analysis we are only going to use a sample of this larger dataset, namely the House of Commons' debates which mention the word \"Brexit\" in the years between 2017 and 2019"
      ],
      "metadata": {
        "id": "a3C8YXv5tUkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "DS0GnNu5tnTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read in the dataframe (df)\n",
        "# you can see how we are using a method from the pandas library, namely the read_csv method to read in csv files and parse them into Python\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/joshcova/NLP_Workshop/refs/heads/main/data/brexit_data.csv\")"
      ],
      "metadata": {
        "id": "Nag7SpuGxajf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summary statistics, though not particularly helpful here\n",
        "\n",
        "df[\"date\"].describe()"
      ],
      "metadata": {
        "id": "W_feT6Z3DMSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the types of the different variables (think string, integer etc...)\n",
        "df.dtypes"
      ],
      "metadata": {
        "id": "9DfweIiZDQZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we can tabulate the observations (here the unit of analysis is the parliamentary speech) by party group\n",
        "df[\"party\"].value_counts()"
      ],
      "metadata": {
        "id": "GdviazuTDBc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If we are only interested in subsetting the dataset to include only parliamentary interventions made by Conservative MPs, we can select for the rows where the value in the \"party\"\n",
        "# column is \"Conservative party\"\n",
        "\n",
        "df2 = df[df[\"party\"] == \"Conservative Party\"]\n"
      ],
      "metadata": {
        "id": "b505sOk6BS79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Now that we have created a new dataset called df2, which, as a reminder, contains all parliamentary speeches made by Conservative MPs which mention the word \"Brexit\" in the years\n",
        "## 2017-2019, we can subset the data to only include rows in which the character length of the text variable is not 0. In other words, we exclude rows with no data.\n",
        "## Thankfully as you can see by running df2.shape (see below) nothing has changed, meaning that we did not have text values containing no words.\n",
        "\n",
        "df2 = df2[df2[\"text\"].str.len()!= 0]"
      ],
      "metadata": {
        "id": "ftT4Z5yw2l5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# As you can see for the shape attribute, there is no need to include brackets. Any ideas why that could be the case compared to df.head() for example?\n",
        "df2.shape"
      ],
      "metadata": {
        "id": "ptoBl6dMBYku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us filter by date and only include the values after 01.01.2018\n",
        "df2['date'] = pd.to_datetime(df2['date'])\n",
        "df_conservative_2018 = df2[(df2[\"date\"] > \"2018-01-01\")]"
      ],
      "metadata": {
        "id": "A_eQjPwKBvgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_conservative_2018.shape"
      ],
      "metadata": {
        "id": "Dh4bShpyCF2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us drop the first column to make the code look a bit cleaner!\n",
        "\n",
        "df_conservative_2018 = df_conservative_2018.drop([\"Unnamed: 0\"], axis=1)"
      ],
      "metadata": {
        "id": "NUzsNWDMCNB1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}